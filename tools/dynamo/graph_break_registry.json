{
  "GB1001": {
    "Version": "v1.0",
    "Gb_type": "Attempted to call a super() attribute that is  not a function or method",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo does not know how to trace the call  `super().{name}()` because `super().{name}` is not a  function or method attribute.",
    "Hints": [
      "Ensure the attribute accessed via `super()` is a standard method or function."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 372,
    "Has_dynamic": false
  },
  "GB1002": {
    "Version": "v1.0",
    "Gb_type": "Argument of `as_subclass` must be a non-dispatcher-style tensor subclass",
    "Context": "{self}.as_subclass({cls})",
    "Explanation": "Currently not supported",
    "Hints": [
      "Avoid this call or move it outside `torch.compile` regione"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/tensor.py",
    "Line": 808,
    "Has_dynamic": false
  },
  "GB1003": {
    "Version": "v1.0",
    "Gb_type": "Assertion failed on symbolic shapes",
    "Context": "str(sym_expr)",
    "Explanation": "",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 680,
    "Has_dynamic": false
  },
  "GB1004": {
    "Version": "v1.0",
    "Gb_type": "Attempt to compile graph in a try block",
    "Context": "",
    "Explanation": "Dynamo cannot compile traced graphs while in a try block.",
    "Hints": [
      "This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 1140,
    "Has_dynamic": false
  },
  "GB1005": {
    "Version": "v1.0",
    "Gb_type": "Attempt to trace generator",
    "Context": "",
    "Explanation": "Generators cannot be compiled directly with `torch.compile`.",
    "Hints": [
      "Call a generator from inside of a non-generator Python function and  compile that function instead."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/convert_frame.py",
    "Line": 554,
    "Has_dynamic": false
  },
  "GB1006": {
    "Version": "v1.0",
    "Gb_type": "Attempted super().__delattr__() on an object without mutation tracking",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo needs to track mutations on an object  before `super().__delattr__` can be used on it. But the  object ({self.objvar}) doesn't have attribute mutation  tracking enabled.",
    "Hints": [
      "Ensure the object is tracked by Dynamo's side effect system."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 286,
    "Has_dynamic": false
  },
  "GB1007": {
    "Version": "v1.0",
    "Gb_type": "Attempted to a str() method implemented in C/C++",
    "Context": "",
    "Explanation": "{type(arg.value)} has a C/C++ based str method. This is not supported.",
    "Hints": [
      "Write the str method in Python"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1307,
    "Has_dynamic": false
  },
  "GB1008": {
    "Version": "v1.0",
    "Gb_type": "Attempted to call function marked as skipped",
    "Context": "module: {module_name}, qualname: {qualname}, skip reason: {reason}",
    "Explanation": "explanation",
    "Hints": "hints",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1470,
    "Has_dynamic": false
  },
  "GB1009": {
    "Version": "v1.0",
    "Gb_type": "Attempted to guard on uninitialized nn.Module",
    "Context": "",
    "Explanation": "Attempted to setup an NN_MODULE guard on uninitialized  nn.Module subclass `{type(val)}`.",
    "Hints": [
      "Ensure the `nn.Module` subclass instance has called `super().__init__()`."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/guards.py",
    "Line": 1789,
    "Has_dynamic": false
  },
  "GB1010": {
    "Version": "v1.0",
    "Gb_type": "Attempted to inline function marked as skipped",
    "Context": "qualname: {fn_qualname}, name: {func.get_name()},  filename: `{func.get_filename()}`, skip reason: {result.reason}",
    "Explanation": "Dynamo developers have intentionally marked that the function `{fn_qualname}`  should not be traced.",
    "Hints": "hints",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3787,
    "Has_dynamic": false
  },
  "GB1011": {
    "Version": "v1.0",
    "Gb_type": "Attempted to inline function marked as skipped (SkipFunctionVariable)",
    "Context": "Attempted to inline a SkipFunctionVariable {func}",
    "Explanation": "Attempted to inline a function that was previously determined to be marked as intentionally skipped.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3829,
    "Has_dynamic": false
  },
  "GB1012": {
    "Version": "v1.0",
    "Gb_type": "Attempted to read a deleted variable",
    "Context": "item: {item}, name: {name}",
    "Explanation": "",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 209,
    "Has_dynamic": false
  },
  "GB1013": {
    "Version": "v1.0",
    "Gb_type": "Attempted to read undefined local variable",
    "Context": "LOAD_FAST {name}",
    "Explanation": "Could not find a local variable with name `{name}`",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1422,
    "Has_dynamic": false
  },
  "GB1014": {
    "Version": "v1.0",
    "Gb_type": "Attempted to read undefined local variable (implicit)",
    "Context": "LOAD_FAST {name}",
    "Explanation": "Could not find an implicit local variable with name `{name}`",
    "Hints": [
      "This happens in dict/list comprehensions"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1412,
    "Has_dynamic": false
  },
  "GB1015": {
    "Version": "v1.0",
    "Gb_type": "Attempted to represent unregistered RemovableHandle",
    "Context": "",
    "Explanation": "Dynamo attempted to build a representation of a torch.utils.hooks.RemovableHandle,  which is not supported. This happens because the RemovableHandle was created in another frame.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 526,
    "Has_dynamic": false
  },
  "GB1016": {
    "Version": "v1.0",
    "Gb_type": "Attempted to wrap RNN, GRU, or LSTM",
    "Context": "str(value)",
    "Explanation": "Dynamo does not support RNN, GRU, or LSTM.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1661,
    "Has_dynamic": false
  },
  "GB1017": {
    "Version": "v1.0",
    "Gb_type": "Attempted to wrap sparse Tensor",
    "Context": "",
    "Explanation": "torch.compile does not support sparse Tensors",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1932,
    "Has_dynamic": false
  },
  "GB1018": {
    "Version": "v1.0",
    "Gb_type": "Attempted to wrap strided NestedTensor",
    "Context": "",
    "Explanation": "torch.compile does not support strided NestedTensor",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1916,
    "Has_dynamic": false
  },
  "GB1019": {
    "Version": "v1.0",
    "Gb_type": "Attempted to wrap torch._higher_order_ops.invoke_subgraph",
    "Context": "",
    "Explanation": "Directly using invoke_subgraph is not supported. Use mark_compile_region",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 936,
    "Has_dynamic": false
  },
  "GB1020": {
    "Version": "v1.0",
    "Gb_type": "Attempted to wrap unbacked SymInt",
    "Context": "",
    "Explanation": "Unbacked SymInt input is not supported yet.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1065,
    "Has_dynamic": false
  },
  "GB1021": {
    "Version": "v1.0",
    "Gb_type": "AutogradFunctionContextVariable escaped Dynamo-traced region",
    "Context": "",
    "Explanation": "We cannot reconstruct a torch.autograd.Function's context object.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 625,
    "Has_dynamic": false
  },
  "GB1022": {
    "Version": "v1.0",
    "Gb_type": "BUILD_STRING key conflict",
    "Context": "format_string_parts: {format_string_parts}, kwargs: {kwargs}, part.sym_kwargs: {part.sym_kwargs}",
    "Explanation": "Failed to build format string due to key conflict",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2695,
    "Has_dynamic": false
  },
  "GB1023": {
    "Version": "v1.0",
    "Gb_type": "BUILD_STRING type error",
    "Context": "str(part)",
    "Explanation": "Format string part type is not correct - expected constant or format string.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2703,
    "Has_dynamic": false
  },
  "GB1024": {
    "Version": "v1.0",
    "Gb_type": "Bad import result",
    "Context": "typestr(value)",
    "Explanation": "Import result is not a Python module.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1640,
    "Has_dynamic": false
  },
  "GB1025": {
    "Version": "v1.0",
    "Gb_type": "Builtin `operator.*` comparison with constant `self` failed",
    "Context": "call_method {self} {name} {args} {kwargs}",
    "Explanation": "Failed to compare {self} with {other}, \" + f\"because {other} is not a Python constant or its mutation check fails.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 510,
    "Has_dynamic": false
  },
  "GB1026": {
    "Version": "v1.0",
    "Gb_type": "CLEANUP_THROW with StopIteration",
    "Context": "",
    "Explanation": "Received StopIteration when handling generator.throw/close. This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1815,
    "Has_dynamic": false
  },
  "GB1027": {
    "Version": "v1.0",
    "Gb_type": "Call to `torch._dynamo.graph_break()`",
    "Context": "Called `torch._dynamo.graph_break()` with args `{args}`, kwargs `{kwargs}`",
    "Explanation": "User-inserted graph break. Message: {graph_break_msg}",
    "Hints": [
      "Remove the `torch._dynamo.graph_break()` call."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1385,
    "Has_dynamic": false
  },
  "GB1028": {
    "Version": "v1.0",
    "Gb_type": "Calling subclass default constructor with more than tensor argument",
    "Context": "{self.value}(args={args}, kwargs={kwargs})",
    "Explanation": "Currently not supported",
    "Hints": [
      "Avoid this constructor call or move it outside  `torch.compile` regione"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/tensor.py",
    "Line": 1481,
    "Has_dynamic": false
  },
  "GB1029": {
    "Version": "v1.0",
    "Gb_type": "Cannot check Tensor object identity without its fake value",
    "Context": "str(fake_tensor)",
    "Explanation": "TensorVariable is missing a fake example_value.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 2562,
    "Has_dynamic": false
  },
  "GB1030": {
    "Version": "v1.0",
    "Gb_type": "Caught non-Exception value",
    "Context": "str(exc_instance)",
    "Explanation": "Except expects to recieve an object of Exception type but received {exc_instance}.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2095,
    "Has_dynamic": false
  },
  "GB1031": {
    "Version": "v1.0",
    "Gb_type": "ComptimeContext graph break",
    "Context": "msg",
    "Explanation": "Manually triggered ComptimeContext graph break with message {msg}.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/comptime.py",
    "Line": 194,
    "Has_dynamic": false
  },
  "GB1032": {
    "Version": "v1.0",
    "Gb_type": "Data dependent operator",
    "Context": "str(cause.func)",
    "Explanation": "Operator `{cause.func}` has a non-Tensor output  whose value is dependent on the data of Tensor inputs.",
    "Hints": "hints",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3229,
    "Has_dynamic": false
  },
  "GB1033": {
    "Version": "v1.0",
    "Gb_type": "Data-dependent assertion failed (cannot compile partial graph)",
    "Context": "value: {value}",
    "Explanation": "Dynamo has determined when encountering a data-dependent assert failure  that it should not compile the partial graph.",
    "Hints": [
      "Use `torch._assert()` to raise a hard AssertionError when the check fails.  This error will propagate back the user code  that called the compiled function (i.e. Dynamo wil not trace any exception handling).",
      "Remove the assert statement.",
      "Move the assert statement outside of any context managers in order to graph break with  partial graph compilation (if fullgraph=False)."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 641,
    "Has_dynamic": false
  },
  "GB1034": {
    "Version": "v1.0",
    "Gb_type": "Data-dependent branching with non-constant __bool__",
    "Context": "method: {x}, result: {result}",
    "Explanation": "Attempted to perform data-dependent branching on a user-defined  object with a __bool__ method that did not return a constant.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 756,
    "Has_dynamic": false
  },
  "GB1035": {
    "Version": "v1.0",
    "Gb_type": "Dynamic shape operator",
    "Context": "str(cause.func)",
    "Explanation": "Operator `{cause.func}`'s output shape depends on input Tensor data.",
    "Hints": [
      "Enable tracing of dynamic shape operators with  `torch._dynamo.config.capture_dynamic_output_shape_ops = True`"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3240,
    "Has_dynamic": false
  },
  "GB1036": {
    "Version": "v1.0",
    "Gb_type": "Dynamic shape operator (no meta kernel)",
    "Context": "str(cause.func)",
    "Explanation": "Operator `{cause.func}` does not have a meta kernel that supports dynamic output shapes",
    "Hints": [
      "Please report an issue to PyTorch"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3250,
    "Has_dynamic": false
  },
  "GB1037": {
    "Version": "v1.0",
    "Gb_type": "Dynamic slicing with Tensor arguments",
    "Context": "SliceVariable start: {start}, stop: {stop}, step: {step}",
    "Explanation": "Creating slices with Tensor arguments is not supported.  e.g. `l[:x]`, where `x` is a 1-element tensor.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 1026,
    "Has_dynamic": false
  },
  "GB1038": {
    "Version": "v1.0",
    "Gb_type": "Dynamo cache limit exceeded",
    "Context": "Limit type: {limit_type}",
    "Explanation": "Dynamo attempted to recompile the code object too many times,  exceeding the {limit_type} cache size limit. Giving up on compiling as the compile time tradeoff is likely not  worth the performance gain.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/convert_frame.py",
    "Line": 1021,
    "Has_dynamic": false
  },
  "GB1039": {
    "Version": "v1.0",
    "Gb_type": "Encountered aliasing during higher order op tracing for HOP - {source_target.name()}",
    "Context": "context",
    "Explanation": "Higher order ops do not support aliasing",
    "Hints": [
      "Consider using the debug context to change user code to avoid aliasing.",
      "Please open an issue."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/higher_order_ops.py",
    "Line": 826,
    "Has_dynamic": true
  },
  "GB1040": {
    "Version": "v1.0",
    "Gb_type": "Encountered input mutation during higher order op tracing for HOP - {source_target.name()}",
    "Context": "context",
    "Explanation": "Higher order ops do not support input mutation",
    "Hints": [
      "Consider using the debug context to change user code to avoid mutation.",
      "Please open an issue."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/higher_order_ops.py",
    "Line": 812,
    "Has_dynamic": true
  },
  "GB1041": {
    "Version": "v1.0",
    "Gb_type": "Encountered non user function variable during invoke_subgraph HOP tracing : {fn_vt}",
    "Context": "",
    "Explanation": "invoke_subgraph does not support non user function variable",
    "Hints": "graph_break_hints.SUPPORTABLE",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/higher_order_ops.py",
    "Line": 3333,
    "Has_dynamic": true
  },
  "GB1042": {
    "Version": "v1.0",
    "Gb_type": "Encountered non-PT2-compliant op",
    "Context": "",
    "Explanation": "msg +   + err_epilogue",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 2017,
    "Has_dynamic": false
  },
  "GB1043": {
    "Version": "v1.0",
    "Gb_type": "Encountered strided NestedTensor in automatic dynamic dim determination",
    "Context": "",
    "Explanation": "torch.compile does not support strided NestedTensor",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 2950,
    "Has_dynamic": false
  },
  "GB1044": {
    "Version": "v1.0",
    "Gb_type": "Encountered tensor.is_inference() during tracing",
    "Context": "",
    "Explanation": "tensor.is_inference() is not supported",
    "Hints": [
      "This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/tensor.py",
    "Line": 722,
    "Has_dynamic": false
  },
  "GB1045": {
    "Version": "v1.0",
    "Gb_type": "Encountered torch.is_inference_mode_enabled during tracing",
    "Context": "",
    "Explanation": "torch.is_inference_mode_enabled() is not supported",
    "Hints": [
      "This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/torch.py",
    "Line": 535,
    "Has_dynamic": false
  },
  "GB1046": {
    "Version": "v1.0",
    "Gb_type": "Encountered unconverted argument when attempting to inline",
    "Context": "func: {func}, arg: {v}",
    "Explanation": "An argument to an inlined function was not successfully converted to a VariableTracker.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3858,
    "Has_dynamic": false
  },
  "GB1047": {
    "Version": "v1.0",
    "Gb_type": "Error when attempting to resolve op packet",
    "Context": "",
    "Explanation": "str(e)",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 2059,
    "Has_dynamic": false
  },
  "GB1048": {
    "Version": "v1.0",
    "Gb_type": "Exception with bad expected type",
    "Context": "str(expected_exc_types)",
    "Explanation": "`except ...` has unsupported type {expected_exc_types}.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2086,
    "Has_dynamic": false
  },
  "GB1049": {
    "Version": "v1.0",
    "Gb_type": "Exception with non-type expectation",
    "Context": "str(expected_type)",
    "Explanation": "`except ...` expects a non-type: {expected_type}.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2118,
    "Has_dynamic": false
  },
  "GB1050": {
    "Version": "v1.0",
    "Gb_type": "Excessive RestartAnalysis() calls",
    "Context": "",
    "Explanation": "Dynamo attempted to trace the same frame 100+ times.  Giving up on compiling as the compile time tradeoff is likely not  worth the performance gain.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/convert_frame.py",
    "Line": 831,
    "Has_dynamic": false
  },
  "GB1051": {
    "Version": "v1.0",
    "Gb_type": "FSDP with use_orig_params=False",
    "Context": "",
    "Explanation": "Dynamo only supports FSDP with use_orig_params=True",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1675,
    "Has_dynamic": false
  },
  "GB1052": {
    "Version": "v1.0",
    "Gb_type": "Failed to construct Enum variable",
    "Context": "value: {value_vt}, allowed enum values: {list(cls_type)}",
    "Explanation": "Attempted to construct an Enum value that is non-constant (e.g. int, string)  or is not an acceptable value for the Enum.  Acceptable values for Enum `{cls_type}`: {list(cls_type)}.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/constant.py",
    "Line": 240,
    "Has_dynamic": false
  },
  "GB1053": {
    "Version": "v1.0",
    "Gb_type": "Failed to convert args/kwargs to proxy",
    "Context": "call_function args: {typestr(*args)} {typestr(*list(kwargs.values()))}",
    "Explanation": "Missing `as_proxy()` implementation for some arg/kwarg.",
    "Hints": "[]",
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 1173,
    "Has_dynamic": false
  },
  "GB1054": {
    "Version": "v1.0",
    "Gb_type": "Failed to mutate tensor data attribute",
    "Context": "setattr({obj}, {name}, {val})",
    "Explanation": "Dyanmo only supports mutating `.data`  of tensor created outside `torch.compile` region",
    "Hints": [
      "Don't mutate `.data` on this tensor, or move  the mutation out of `torch.compile` region"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2115,
    "Has_dynamic": false
  },
  "GB1055": {
    "Version": "v1.0",
    "Gb_type": "Failed to raise exception",
    "Context": "str(exc)",
    "Explanation": "Attempted to raise a non-Exception type/value.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1775,
    "Has_dynamic": false
  },
  "GB1056": {
    "Version": "v1.0",
    "Gb_type": "Failed to set tensor attribute",
    "Context": "setattr({obj}, {name}, {val})",
    "Explanation": "Dyanmo doesn't support setting these tensor attributes",
    "Hints": [
      "Don't mutate attribute '{name}' on tensors, or  move the mutation out of `torch.compile` region"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2180,
    "Has_dynamic": false
  },
  "GB1057": {
    "Version": "v1.0",
    "Gb_type": "Failed to trace builtin operator",
    "Context": "builtin {fn.__name__} {arg_types} {has_kwargs}",
    "Explanation": "Dynamo does not know how to trace builtin operator `{fn.__name__}`  with argument types {real_arg_types} (has_kwargs {has_kwargs})",
    "Hints": [
      "Avoid calling builtin `{fn.__name__}` with argument types {real_arg_types}. ",
      "Consider using an equivalent alternative function/method to `{fn.__name__}`.",
      "If you are attempting to call a logging function (e.g. `print`),  you can try adding it to `torch._dynamo.config.reorderable_logging_functions`.",
      "Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 951,
    "Has_dynamic": false
  },
  "GB1058": {
    "Version": "v1.0",
    "Gb_type": "Failed to trace unittest method",
    "Context": "function: unittest.TestCase.{name}",
    "Explanation": "Dynamo does not know how to trace unittest method `{name}` ",
    "Hints": [
      "Avoid calling `TestCase.{name}`.  Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2016,
    "Has_dynamic": false
  },
  "GB1059": {
    "Version": "v1.0",
    "Gb_type": "Failed to unpack object for BUILD_LIST_UNPACK",
    "Context": "str(seq)",
    "Explanation": "{seq} cannot be unpacked into a list for the BUILD_LIST_UNPACK  bytecode (`[*x, *y, ...]`).",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2427,
    "Has_dynamic": false
  },
  "GB1060": {
    "Version": "v1.0",
    "Gb_type": "Failed to unpack object for UNPACK_EX",
    "Context": "str(seq)",
    "Explanation": "{seq} cannot be unpacked into a list for the UNPACK_EX bytecode.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2595,
    "Has_dynamic": false
  },
  "GB1061": {
    "Version": "v1.0",
    "Gb_type": "Failed to unpack object for UNPACK_SEQUENCE",
    "Context": "str(seq)",
    "Explanation": "{seq} cannot be unpacked into a list for the UNPACK_SEQUENCE bytecode  (i.e. `a, b, c = d`).",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2560,
    "Has_dynamic": false
  },
  "GB1062": {
    "Version": "v1.0",
    "Gb_type": "Fake tensor propagation exception",
    "Context": "str(e.reason)",
    "Explanation": "msg",
    "Hints": "[]",
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 2706,
    "Has_dynamic": false
  },
  "GB1063": {
    "Version": "v1.0",
    "Gb_type": "Graph break in inlined function",
    "Context": "",
    "Explanation": "Graph breaks in an inlined call are not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 4052,
    "Has_dynamic": false
  },
  "GB1064": {
    "Version": "v1.0",
    "Gb_type": "Graph break under GenericContextWrappingVariable",
    "Context": "Active generic context managers: {self.active_generic_context_managers}",
    "Explanation": "Attempted to graph break in an active context manager(s) that doesn't support graph breaking.",
    "Hints": [
      "Move the offending context manager(s) to outside the compiled region."
    ],
    "From_exc": "excp",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 834,
    "Has_dynamic": false
  },
  "GB1065": {
    "Version": "v1.0",
    "Gb_type": "HigherOrderOperator: Mutating a variable not in the current scope (SideEffects)",
    "Context": "",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 190,
    "Has_dynamic": false
  },
  "GB1066": {
    "Version": "v1.0",
    "Gb_type": "Import failure",
    "Context": "module_name: {module_name}, fromlist: {fromlist}, level={level}",
    "Explanation": "Failure when attempting to import.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1612,
    "Has_dynamic": false
  },
  "GB1067": {
    "Version": "v1.0",
    "Gb_type": "Indexing list with non-scalar tensor",
    "Context": "call_method {self} {name} {args} {kwargs}",
    "Explanation": "Attempted to index list-like object with tensor with > 1 element.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 140,
    "Has_dynamic": false
  },
  "GB1068": {
    "Version": "v1.0",
    "Gb_type": "Inline attempt with __self__",
    "Context": "str(func)",
    "Explanation": "Attempted to inline a function with the `__self__` attribute.  Dynamo is expected to decompose method calls into function calls with a `self` argument.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3739,
    "Has_dynamic": false
  },
  "GB1069": {
    "Version": "v1.0",
    "Gb_type": "Inplace op on input tensor",
    "Context": "",
    "Explanation": "Attempted to trace an inplace view op on input tensor {typestr(self.value)}.",
    "Hints": [
      "Ensure you do not modify input tensor in place."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/torch.py",
    "Line": 1224,
    "Has_dynamic": false
  },
  "GB1070": {
    "Version": "v1.0",
    "Gb_type": "Invoking an nn.Module inside a HigherOrderOperator",
    "Context": "",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 2344,
    "Has_dynamic": false
  },
  "GB1071": {
    "Version": "v1.0",
    "Gb_type": "Invoking an nn.Module inside a higher order operator",
    "Context": "Higher order op name: {self.source_target}",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 2310,
    "Has_dynamic": false
  },
  "GB1072": {
    "Version": "v1.0",
    "Gb_type": "LOAD_BUILD_CLASS bytecode not supported",
    "Context": "",
    "Explanation": "Dynamo does not support tracing classes that are defined in the compiled region.",
    "Hints": [
      "Move the class definition out of the compiled region."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2818,
    "Has_dynamic": false
  },
  "GB1073": {
    "Version": "v1.0",
    "Gb_type": "LOAD_FAST_CHECK on uninitialized variable",
    "Context": "inst.argval",
    "Explanation": "Attempted to load uninitialized local variable {inst.argval}",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3048,
    "Has_dynamic": false
  },
  "GB1074": {
    "Version": "v1.0",
    "Gb_type": "Length mismatch when unpacking object for UNPACK_SEQUENCE",
    "Context": "expected length: {inst.argval}, actual: {len(val)}",
    "Explanation": "{seq} unpacked to a list for the UNPACK_SEQUENCE bytecode  (i.e. `a, b, c = d`) with unexpected length.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2568,
    "Has_dynamic": false
  },
  "GB1075": {
    "Version": "v1.0",
    "Gb_type": "Limitation of `nonstrict_trace",
    "Context": "{self}",
    "Explanation": "msg",
    "Hints": [
      "make sure definition of {fn_name} is outside ",
      "`torch.compile` region"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 485,
    "Has_dynamic": false
  },
  "GB1076": {
    "Version": "v1.0",
    "Gb_type": "Missing CALL_INTRINSIC_1 handler",
    "Context": "CALL_INTRINSIC_1 operand: {inst.argval}",
    "Explanation": "No handler implemented for CALL_INTRINSIC_1 {inst.argval} instruction.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3081,
    "Has_dynamic": false
  },
  "GB1077": {
    "Version": "v1.0",
    "Gb_type": "Missing FakeTensor example value",
    "Context": "str(node)",
    "Explanation": "`FakeTensor` example value was required for {node} but not available.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3090,
    "Has_dynamic": false
  },
  "GB1078": {
    "Version": "v1.0",
    "Gb_type": "Missing attribute when running call_method node",
    "Context": "",
    "Explanation": "make_error_message(\"attribute not defined\")",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3373,
    "Has_dynamic": false
  },
  "GB1079": {
    "Version": "v1.0",
    "Gb_type": "Missing bytecode handler",
    "Context": "{opname} with args {args}",
    "Explanation": "Dynamo does not know how to handle the bytecode instruction `{opname}`.",
    "Hints": [
      "Do not trace code that produces the `{opname}` bytecode instruction  (see https://docs.python.org/3/library/dis.html for bytecode semantics)."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 952,
    "Has_dynamic": false
  },
  "GB1080": {
    "Version": "v1.0",
    "Gb_type": "Module-level backwards hooks require compiled autograd.",
    "Context": "",
    "Explanation": "",
    "Hints": [
      "Enable compiled autograd by setting torch._dynamo.config.compiled_autograd = True."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/distributed.py",
    "Line": 353,
    "Has_dynamic": false
  },
  "GB1081": {
    "Version": "v1.0",
    "Gb_type": "Non-constant attribute given to `super().__delattr__()`",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo requires the attribute name passed to  `super().__delattr__(...)` to be a constant (string).",
    "Hints": [
      "Ensure the attribute name is a string literal or a constant variable."
    ],
    "From_exc": "exc",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 275,
    "Has_dynamic": false
  },
  "GB1082": {
    "Version": "v1.0",
    "Gb_type": "Non-function or method in subclass of torch.autograd.Function",
    "Context": "call_apply {self} {args} {kwargs}",
    "Explanation": "Dynamo requires the `forward` attribute of a  `torch.autograd.Function` subclass to be a standard Python  function or method. Found type `{type(fn).__name__}` instead.",
    "Hints": [
      "Ensure the `forward` method is defined as a regular  function or instance method."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 767,
    "Has_dynamic": false
  },
  "GB1083": {
    "Version": "v1.0",
    "Gb_type": "Not a Python constant",
    "Context": "guard_as_python_constant {self}",
    "Explanation": "Failed to convert {self} into a Python constant.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 349,
    "Has_dynamic": false
  },
  "GB1084": {
    "Version": "v1.0",
    "Gb_type": "NotImplementedError/UnsupportedFakeTensorException when running FX node",
    "Context": "",
    "Explanation": "make_error_message(e)",
    "Hints": "hints",
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3399,
    "Has_dynamic": false
  },
  "GB1085": {
    "Version": "v1.0",
    "Gb_type": "Observed exception",
    "Context": "str(raised_exception)",
    "Explanation": "observed_exn_gb_explanation",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1914,
    "Has_dynamic": false
  },
  "GB1086": {
    "Version": "v1.0",
    "Gb_type": "Observed exception (EXCEPT_HANDLER)",
    "Context": "str(raised_exception)",
    "Explanation": "observed_exn_gb_explanation + \" This graph break is unexpected.\"",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1940,
    "Has_dynamic": false
  },
  "GB1087": {
    "Version": "v1.0",
    "Gb_type": "Operator does not support running with fake tensors",
    "Context": "unsupported operator: {cause.func}",
    "Explanation": "",
    "Hints": [
      "{import_suggestion}see  https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit#heading=h.64r4npvq0w0  for how to fix"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3274,
    "Has_dynamic": false
  },
  "GB1088": {
    "Version": "v1.0",
    "Gb_type": "Read uninitialized cell",
    "Context": "str(cellvar)",
    "Explanation": "Attempted to read a cell variable that has not been populated yet.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 235,
    "Has_dynamic": false
  },
  "GB1089": {
    "Version": "v1.0",
    "Gb_type": "Reconstruction failure",
    "Context": "str(value)",
    "Explanation": "Dynamo has no bytecode reconstruction implemented for sourceless variable {value}.",
    "Hints": [
      "If Dynamo is attempting to trace a return statement and your code is attempting to return a variable  that Dynamo cannot reconstruct, then remove it from the return statement.",
      "Report an issue to PyTorch if you need reconstrtuction support. Note that objects that don't have  reconstruction rules may be fundamentally unreconstructable."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/codegen.py",
    "Line": 347,
    "Has_dynamic": false
  },
  "GB1090": {
    "Version": "v1.0",
    "Gb_type": "Reconstruction failure: source.reconstruct not implemented",
    "Context": "str(source)",
    "Explanation": "Dynamo has no bytecode reconstruction implemented for {type(source)} variable {source}.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/codegen.py",
    "Line": 204,
    "Has_dynamic": false
  },
  "GB1091": {
    "Version": "v1.0",
    "Gb_type": "SEND with bad type",
    "Context": "TOS type: {typestr(tos)}",
    "Explanation": "Attempted to SEND with unsupported type {typestr(tos)}.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 4248,
    "Has_dynamic": false
  },
  "GB1092": {
    "Version": "v1.0",
    "Gb_type": "Set Exception object `__traceback__` attribute to not-`None`",
    "Context": "call_setattr {self} {name}",
    "Explanation": "Dynamo does not support setting the attribute  '__traceback__' on tracked exception objects to anything  other than None.",
    "Hints": [
      "Avoid setting '__traceback__' on exception objects  within traced code, or set it to None."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 466,
    "Has_dynamic": false
  },
  "GB1093": {
    "Version": "v1.0",
    "Gb_type": "Should not compile partial graph (STORE_ATTR)",
    "Context": "",
    "Explanation": "Dynamo has determined when encountering an unsupported  STORE_ATTR instruction (i.e. `obj.attr = val`) that it should not compile the partial graph.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2353,
    "Has_dynamic": false
  },
  "GB1094": {
    "Version": "v1.0",
    "Gb_type": "Side effect on existing deque with limited maxlen",
    "Context": "",
    "Explanation": "This is not supported.",
    "Hints": [
      "Don't use a deque with `maxlen` specified."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 774,
    "Has_dynamic": false
  },
  "GB1095": {
    "Version": "v1.0",
    "Gb_type": "Skip calling `torch.compiler.disable()`d function",
    "Context": "str(self.value)",
    "Explanation": "Skip calling function `{self.value}` since it was wrapped  with `torch.compiler.disable` (reason: {msg})",
    "Hints": [
      "Remove the `torch.compiler.disable` call"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1372,
    "Has_dynamic": false
  },
  "GB1096": {
    "Version": "v1.0",
    "Gb_type": "Skip inlining `torch.compiler.disable()`d function",
    "Context": "str(func.get_function())",
    "Explanation": "Skip inlining function {func.get_function()} since it was wrapped  with `torch.compiler.disable` (reason: {msg})",
    "Hints": [
      "Remove the `torch.compiler.disable` call"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3753,
    "Has_dynamic": false
  },
  "GB1097": {
    "Version": "v1.0",
    "Gb_type": "Storing Tensor hook handle in globals",
    "Context": "name",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 1520,
    "Has_dynamic": false
  },
  "GB1098": {
    "Version": "v1.0",
    "Gb_type": "Storing Tensor hook handle in globals (inline call)",
    "Context": "inst.argval",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 4120,
    "Has_dynamic": false
  },
  "GB1099": {
    "Version": "v1.0",
    "Gb_type": "Tensor subclass overriden method call",
    "Context": "{name}",
    "Explanation": "`torch.compile` currently can't trace this",
    "Hints": [
      "Avoid calling {name} of tensor subclass in torch.compile region",
      "Renaming method `{name}` of type {self.class_type}"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/torch_function.py",
    "Line": 739,
    "Has_dynamic": false
  },
  "GB1100": {
    "Version": "v1.0",
    "Gb_type": "Tensor.random_ op called with `from` keyword",
    "Context": "",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2208,
    "Has_dynamic": false
  },
  "GB1101": {
    "Version": "v1.0",
    "Gb_type": "Tensor.uniform_ op called with `from` keyword",
    "Context": "",
    "Explanation": "This is not supported.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2226,
    "Has_dynamic": false
  },
  "GB1102": {
    "Version": "v1.0",
    "Gb_type": "TypeError from user code",
    "Context": "call_function({self.value}, {args}, {kwargs})",
    "Explanation": "msg",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 473,
    "Has_dynamic": false
  },
  "GB1103": {
    "Version": "v1.0",
    "Gb_type": "TypeError when making fake tensor call",
    "Context": "TypeError {node.target}: {cause}",
    "Explanation": "",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/utils.py",
    "Line": 3295,
    "Has_dynamic": false
  },
  "GB1104": {
    "Version": "v1.0",
    "Gb_type": "Unable to resolve super getattr",
    "Context": "",
    "Explanation": "Dynamo failed to trace attribute `{name}` accessed  via `super()` (for type `{self.typevar}` and object `{self.objvar}`)  because the resolved attribute type is not supported.",
    "Hints": [
      "Ensure the attribute exists in the parent class.",
      "Check the arguments passed to `super()`."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 144,
    "Has_dynamic": false
  },
  "GB1105": {
    "Version": "v1.0",
    "Gb_type": "Unexpected failure during itertools.accumulate() iteration",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Unexpected failure in invoking function during accumulate.  Failed running func {func}({item}{acc})",
    "Hints": [
      "This graph break may be difficult to debug. Please report an issue to PyTorch for assistance."
    ],
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 133,
    "Has_dynamic": false
  },
  "GB1106": {
    "Version": "v1.0",
    "Gb_type": "Unexpected failure during itertools.groupby() iteration",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Unexpected failure in invoking function during groupby",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 232,
    "Has_dynamic": false
  },
  "GB1107": {
    "Version": "v1.0",
    "Gb_type": "Unexpected type in sourceless builder",
    "Context": "{value_type.__module__}.{value_type.__qualname__}",
    "Explanation": "SourcelessBuilder.create does not know how to wrap {value_type}",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 3409,
    "Has_dynamic": false
  },
  "GB1108": {
    "Version": "v1.0",
    "Gb_type": "Uninitialized nn.Module",
    "Context": "typestr(value)",
    "Explanation": "Attempted to trace an uninitialized nn.Module of type {typestr(value)}.",
    "Hints": [
      "Ensure your nn.Module instance has called `super().__init__()`."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1629,
    "Has_dynamic": false
  },
  "GB1109": {
    "Version": "v1.0",
    "Gb_type": "Unreachable sub-generator code",
    "Context": "",
    "Explanation": "Should only be encountered while implementing generator support.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 4183,
    "Has_dynamic": false
  },
  "GB1110": {
    "Version": "v1.0",
    "Gb_type": "UnspecializedNNModuleVariable missing method",
    "Context": "call_method: {self} {name} {args} {kwargs}",
    "Explanation": "Dynamo does not support tracing method {name} of nn.Module {self.value}",
    "Hints": [
      "Dynamo does not really define unspecialized nn.Module very well."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 1044,
    "Has_dynamic": false
  },
  "GB1111": {
    "Version": "v1.0",
    "Gb_type": "Unsupported SourceType",
    "Context": "MutationType.__init__ {self} {typ}",
    "Explanation": "Dynamo does not support the type `{typ}`",
    "Hints": [
      "This branch is not supposed to be reachable."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 92,
    "Has_dynamic": false
  },
  "GB1112": {
    "Version": "v1.0",
    "Gb_type": "Unsupported __setitem__/__setattr__ inline attempt",
    "Context": "code name: {code.co_name}, args: {args}",
    "Explanation": "Attempted to inline {code.co_name} where first argument (self) is not a user-defined object.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3868,
    "Has_dynamic": false
  },
  "GB1113": {
    "Version": "v1.0",
    "Gb_type": "Unsupported `func` in itertools.accumulate",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to get the  function to use for itertools.accumulate.  itertools.accumulate expects the `func` as the second  argument or as a keyword argument.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 98,
    "Has_dynamic": false
  },
  "GB1114": {
    "Version": "v1.0",
    "Gb_type": "Unsupported arguments for itertools.accumulate",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace  itertools.accumulate with args: {args} and kwargs: {kwargs}.  itertools.accumulate expects an iterable, an optional  binary function for accumulation, and an optional initial  value to set the starting state.",
    "Hints": [
      "Make sure the arguments to itertools.accumulate are correct."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 108,
    "Has_dynamic": false
  },
  "GB1115": {
    "Version": "v1.0",
    "Gb_type": "Unsupported arguments for itertools.groupby",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace  itertools.groupby with args: {args} and kwargs: {kwargs}.  itertools.groupby expects an iterable to group and an  optional key function to determine groupings.",
    "Hints": [
      "Make sure the arguments to itertools.groupby are correct."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 190,
    "Has_dynamic": false
  },
  "GB1116": {
    "Version": "v1.0",
    "Gb_type": "Unsupported attribute assignment on Exception object",
    "Context": "call_setattr {self} {name}",
    "Explanation": "Dynamo does not support setting the attribute  '{name}' on tracked exception objects. Only `__context__`,  `__cause__`, `__suppress_context__`, and `__traceback__` are supported.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 478,
    "Has_dynamic": false
  },
  "GB1117": {
    "Version": "v1.0",
    "Gb_type": "Unsupported attribute for range() object",
    "Context": "var_getattr {self} {name}",
    "Explanation": "Expected attribute to be one of {','.join(fields)}  but got {name}",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 351,
    "Has_dynamic": false
  },
  "GB1118": {
    "Version": "v1.0",
    "Gb_type": "Unsupported attribute for slice() object",
    "Context": "var_getattr {self} {name}",
    "Explanation": "Expected attribute to be one of {','.join(fields)}  but got {name}",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 1060,
    "Has_dynamic": false
  },
  "GB1119": {
    "Version": "v1.0",
    "Gb_type": "Unsupported autograd.Function context `save_for_backward`",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo requires the `saved_tensors` attribute  to be initialized on the `autograd.Function` context object.",
    "Hints": [
      "Ensure that the `saved_tensors` attribute is properly  initialized before calling `save_for_backward`.  `save_for_backward` only supported on a newly constructed `torch.autograd.function.FunctionCtx`."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 947,
    "Has_dynamic": false
  },
  "GB1120": {
    "Version": "v1.0",
    "Gb_type": "Unsupported autograd.Function context method",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo does not support calling the method  `{name}` on `autograd.Function` context objects. Supported  methods are `__setattr__`, `save_for_backward` and  `mark_non_differentiable`.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 937,
    "Has_dynamic": false
  },
  "GB1121": {
    "Version": "v1.0",
    "Gb_type": "Unsupported autograd.Function method",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo does not support calling the method  `{name}` directly on the `torch.autograd.Function`  instance. Supported methods include `apply`, `backward`,  static methods, and class methods.",
    "Hints": [
      "Ensure the method is decorated with `@staticmethod`  or `@classmethod` if it's meant to be called on the class."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 843,
    "Has_dynamic": false
  },
  "GB1122": {
    "Version": "v1.0",
    "Gb_type": "Unsupported context manager",
    "Context": "Attempted SETUP_WITH/BEFORE_WITH on {ctx}",
    "Explanation": "Dynamo does not know how to enter a `{ctx.python_type_name()}` context manager.",
    "Hints": [
      "Avoid using the unsupported context manager.",
      "File an issue to PyTorch. Simple context managers can potentially be supported,  but note that context managers can't be supported in general"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2961,
    "Has_dynamic": false
  },
  "GB1123": {
    "Version": "v1.0",
    "Gb_type": "Unsupported conversion for slice assignment",
    "Context": "call_method {self} {name} {args}",
    "Explanation": "Missing dynamo support for converting {value} into a list for slice assignment.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 474,
    "Has_dynamic": false
  },
  "GB1124": {
    "Version": "v1.0",
    "Gb_type": "Unsupported custom jvp",
    "Context": "call_apply {self} {args} {kwargs}",
    "Explanation": "Dynamo does not support tracing  `torch.autograd.Function` subclasses that define  a custom `jvp` method.",
    "Hints": [
      "Remove the custom `jvp` method if possible."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 705,
    "Has_dynamic": false
  },
  "GB1125": {
    "Version": "v1.0",
    "Gb_type": "Unsupported custom vjp",
    "Context": "call_apply {self} {args} {kwargs}",
    "Explanation": "Dynamo does not support tracing  `torch.autograd.Function` subclasses that define  a custom `vjp` method.",
    "Hints": [
      "Remove the custom `vjp` method if possible.",
      "Use standard `backward` instead if applicable."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 690,
    "Has_dynamic": false
  },
  "GB1126": {
    "Version": "v1.0",
    "Gb_type": "Unsupported function call",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace the function `{self.debug_repr()}`",
    "Hints": [
      "Avoid calling `{self.debug_repr()}` in your code.",
      "Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 464,
    "Has_dynamic": false
  },
  "GB1127": {
    "Version": "v1.0",
    "Gb_type": "Unsupported function call (delayed)",
    "Context": "source: {self.source}",
    "Explanation": "Dynamo determined that a graph break should occur  when calling `{self.source.name()}`. Reason: {self.msg}",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 538,
    "Has_dynamic": false
  },
  "GB1128": {
    "Version": "v1.0",
    "Gb_type": "Unsupported functorch tracing attempt",
    "Context": "",
    "Explanation": "msg",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 3493,
    "Has_dynamic": false
  },
  "GB1129": {
    "Version": "v1.0",
    "Gb_type": "Unsupported hasattr call",
    "Context": "call_obj_hasattr {self} {name}",
    "Explanation": "Dynamo does not know how to trace the function `{self.debug_repr()}`",
    "Hints": [
      "Avoid calling `hasattr({self.__class__.__name__}, {name})` in your code."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 448,
    "Has_dynamic": false
  },
  "GB1130": {
    "Version": "v1.0",
    "Gb_type": "Unsupported inspect call",
    "Context": "inspect_parameter_names {self}",
    "Explanation": "Dynamo does not know how to trace the function `{self.debug_repr()}`",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 438,
    "Has_dynamic": false
  },
  "GB1131": {
    "Version": "v1.0",
    "Gb_type": "Unsupported key type for itertools.groupby",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace  itertools.groupby with key type: {str(type(key))}.  We only support grouping keys that are constants (int, float, str, etc.)",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 178,
    "Has_dynamic": false
  },
  "GB1132": {
    "Version": "v1.0",
    "Gb_type": "Unsupported key type for nn.Module.__getitem__",
    "Context": "call_method: {self} {name} {args} {kwargs}",
    "Explanation": "Dynamo does not support getitem on  `nn.Module` with non-constant key.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 803,
    "Has_dynamic": false
  },
  "GB1133": {
    "Version": "v1.0",
    "Gb_type": "Unsupported kwargs for itertools.accumulate",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Expected kwargs: 'initial', 'func', but got  {','.join(set(kwargs.keys()) - {'initial', 'func'})}",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 79,
    "Has_dynamic": false
  },
  "GB1134": {
    "Version": "v1.0",
    "Gb_type": "Unsupported kwargs for itertools.groupby",
    "Context": "call_function {self} {args} {kwargs}",
    "Explanation": "Expected kwargs: 'key', but got  {','.join(set(kwargs.keys()) - {'key'})}",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 164,
    "Has_dynamic": false
  },
  "GB1135": {
    "Version": "v1.0",
    "Gb_type": "Unsupported method call",
    "Context": "call_method {self} {name} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace method `{name}` of class `{self.python_type_name()}`",
    "Hints": "hints",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 550,
    "Has_dynamic": false
  },
  "GB1136": {
    "Version": "v1.0",
    "Gb_type": "Unsupported next() call",
    "Context": "next({self})",
    "Explanation": "Dynamo does not know how to trace calling `next()` on variable `{self}`.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/base.py",
    "Line": 573,
    "Has_dynamic": false
  },
  "GB1137": {
    "Version": "v1.0",
    "Gb_type": "Unsupported nn.Module attribute type",
    "Context": "nn.Module subclass: {typestr(base)}, name: {name}, attribute type: {typestr(subobj)}",
    "Explanation": "Dynamo does not support tracing nn.Module attributes of type `{typestr(subobj)}`",
    "Hints": [
      "Refactor your code so that `{name}` (type `{typestr(subobj)}`) is not an attribute of `{typestr(base)}`",
      "Currently supported attribute types are methods, classmethods, staticmethods,  properties, constants, and tensors."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 408,
    "Has_dynamic": false
  },
  "GB1138": {
    "Version": "v1.0",
    "Gb_type": "Unsupported super().__init__() call",
    "Context": "call_method {self} {name} {args} {kwargs}",
    "Explanation": "Dynamo encountered a super().__init__() call  on {objvar} that resolved to a `torch.nn.Module.__init__()`  call that we cannot trace.",
    "Hints": [
      "This graph break may be difficult to debug. Please report an issue to PyTorch for assistance."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 204,
    "Has_dynamic": false
  },
  "GB1139": {
    "Version": "v1.0",
    "Gb_type": "Unsupported tensor subclass attribute access",
    "Context": "{name}",
    "Explanation": "`torch.compile` currently can't trace this",
    "Hints": [
      "Avoid accessing {name} of tensor subclass in torch.compile region"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/torch_function.py",
    "Line": 633,
    "Has_dynamic": false
  },
  "GB1140": {
    "Version": "v1.0",
    "Gb_type": "Unsupported tensor subclass overriden attribute access",
    "Context": "{name}",
    "Explanation": "`torch.compile` only support tracing certain types of overriden tensor subclass attributes",
    "Hints": [
      "Avoid accessing {name} of tensor subclass in torch.compile region",
      "Renaming attribute `{name}` of type {self.class_type}"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/torch_function.py",
    "Line": 698,
    "Has_dynamic": false
  },
  "GB1141": {
    "Version": "v1.0",
    "Gb_type": "Unsupported torch._C._ImperativeEngine method",
    "Context": "call_method {self} {name}",
    "Explanation": "Dynamo only supports the `queue_callback` method  on a torch._C._ImperativeEngine instance, but found: `{name}`.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 1029,
    "Has_dynamic": false
  },
  "GB1142": {
    "Version": "v1.0",
    "Gb_type": "Unsupported torch._C._ImperativeEngine.queue_callback()",
    "Context": "call_method {self} {name}",
    "Explanation": "queue_callback() is only supported when  Compiled Autograd is enabled with fullgraph=True.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 1021,
    "Has_dynamic": false
  },
  "GB1143": {
    "Version": "v1.0",
    "Gb_type": "Unsupported {method_name} method",
    "Context": "str(name)",
    "Explanation": "Dynamo doesn't support tracing the {method_name} method.  We currently support wait, record, synchronize, and query.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/ctx_manager.py",
    "Line": 1347,
    "Has_dynamic": true
  },
  "GB1144": {
    "Version": "v1.0",
    "Gb_type": "Variadic function call with bad args/kwargs type",
    "Context": "args type: {typestr(argsvars)}, kwargs type: {typestr(kwargsvars)}",
    "Explanation": "Expected args to be a list and kwargs to be a dict",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2245,
    "Has_dynamic": false
  },
  "GB1145": {
    "Version": "v1.0",
    "Gb_type": "Variadic function call with bad flags",
    "Context": "flags: {inst.argval}",
    "Explanation": "Attempted to call a variadic function (CALL_FUNCTION_EX) with bad flags {inst.argval}",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2168,
    "Has_dynamic": false
  },
  "GB1146": {
    "Version": "v1.0",
    "Gb_type": "Write to immutable cell",
    "Context": "cellvar: {cellvar}, value: {value}",
    "Explanation": "Dynamo doesn't support writing to immutable/sourceless cell variables.",
    "Hints": [
      "This graph break may be difficult to debug. Please report an issue to PyTorch for assistance."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/side_effects.py",
    "Line": 219,
    "Has_dynamic": false
  },
  "GB1147": {
    "Version": "v1.0",
    "Gb_type": "_gb_type",
    "Context": "attempted to jump with {value}",
    "Explanation": "_explanation",
    "Hints": "_hints",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 809,
    "Has_dynamic": false
  },
  "GB1148": {
    "Version": "v1.0",
    "Gb_type": "assert with non-string message",
    "Context": "str(args)",
    "Explanation": "Dynamo only supports asserts with string messages",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 812,
    "Has_dynamic": false
  },
  "GB1149": {
    "Version": "v1.0",
    "Gb_type": "async_op=True for distributed collectives",
    "Context": "{self.fn}, {args=}, {kwargs=}",
    "Explanation": "`torch.compile` doesn't support `async_op=True for {self.fn}",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1628,
    "Has_dynamic": false
  },
  "GB1150": {
    "Version": "v1.0",
    "Gb_type": "backward_state does not support export",
    "Context": "",
    "Explanation": "Compiled autograd doesn't work with `torch.export`.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/output_graph.py",
    "Line": 569,
    "Has_dynamic": false
  },
  "GB1151": {
    "Version": "v1.0",
    "Gb_type": "bad args to builtin cast()",
    "Context": "got args {args} {kwargs}",
    "Explanation": "Dynamo expects exactly 2 args to builtin cast().",
    "Hints": [
      "Ensure your call to cast() has exactly 2 arguments."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1621,
    "Has_dynamic": false
  },
  "GB1152": {
    "Version": "v1.0",
    "Gb_type": "builtin isinstance() cannot determine type of argument",
    "Context": "isinstance({arg}, {isinstance_type})",
    "Explanation": "Dynamo doesn't have a rule to determine the type of argument {arg}",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1772,
    "Has_dynamic": false
  },
  "GB1153": {
    "Version": "v1.0",
    "Gb_type": "can't handle functions not implemented in python ",
    "Context": "{fn}",
    "Explanation": "Dynamo can only handle functions defined in python",
    "Hints": [
      "Move usage of this function out of `torch.compile` region"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 337,
    "Has_dynamic": false
  },
  "GB1154": {
    "Version": "v1.0",
    "Gb_type": "constant fold exception",
    "Context": "attempted to run function {fn} with arguments {args}",
    "Explanation": "Encountered exception when attempting to constant fold.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": "exc",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 910,
    "Has_dynamic": false
  },
  "GB1155": {
    "Version": "v1.0",
    "Gb_type": "copy.deepcopy()",
    "Context": "copy.deepcopy({x})",
    "Explanation": "Dynamo does not support copy.deepcopy()",
    "Hints": [
      "Avoid calling copy.deepcopy()"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2325,
    "Has_dynamic": false
  },
  "GB1156": {
    "Version": "v1.0",
    "Gb_type": "dataclass fields failure",
    "Context": "obj: {obj}; variable type: {type(obj)}",
    "Explanation": "Dataclass fields handling fails for {obj}. Expected it to be a user-defined object.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 2445,
    "Has_dynamic": false
  },
  "GB1157": {
    "Version": "v1.0",
    "Gb_type": "dtype mismatch between tensor and its gradient",
    "Context": "tensor dtype: {value.dtype}; grad dtype: {safe_grad(value).dtype}",
    "Explanation": "Inconsistent dtype between tensor and its gradient.  This can happen in FSDP and crashes meta tensor creation.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1944,
    "Has_dynamic": false
  },
  "GB1158": {
    "Version": "v1.0",
    "Gb_type": "failed to broadcast when attempting Tensor comparison op",
    "Context": "{op.__name__}({left}, {right})",
    "Explanation": "Dynamo was unable to broad cast the arguments {left}, {right}  when attempting to trace the comparison op {op.__name__}.",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2371,
    "Has_dynamic": false
  },
  "GB1159": {
    "Version": "v1.0",
    "Gb_type": "failed to call dict.fromkeys()",
    "Context": "{user_cls.__name__}.fromkeys(): {args} {kwargs}",
    "Explanation": "Failed to call {user_cls.__name__}.fromkeys() because  arguments could not be automatically converted to a list,  or some dict key is not hashable.",
    "Hints": [
      "Manually convert the argument to a list.",
      "Ensure all keys are hashable."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1673,
    "Has_dynamic": false
  },
  "GB1160": {
    "Version": "v1.0",
    "Gb_type": "failed to call str() on user defined object",
    "Context": "str(arg)",
    "Explanation": "User defined object has no __str__ or __repr__ method",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1292,
    "Has_dynamic": false
  },
  "GB1161": {
    "Version": "v1.0",
    "Gb_type": "failed to convert numpy.ndarray to Tensor",
    "Context": "str(value)",
    "Explanation": "Exception encountered when attempting to convert numpy.ndarray to Tensor",
    "Hints": "[]",
    "From_exc": "e",
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 2065,
    "Has_dynamic": false
  },
  "GB1162": {
    "Version": "v1.0",
    "Gb_type": "functools.partial() with non-literal keyword",
    "Context": "non-literal keyword: {k}",
    "Explanation": "functools.partial() expects literal/string keywords",
    "Hints": [
      "Dynamo has detected that tracing the code will result in an error when running in eager. Please double check that your code doesn't contain a similar error when actually running eager/uncompiled."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 802,
    "Has_dynamic": false
  },
  "GB1163": {
    "Version": "v1.0",
    "Gb_type": "functools.wraps",
    "Context": "{fn}",
    "Explanation": "`torch.compile` can't trace `functools.wraps` on functions defined outside the compile region",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1668,
    "Has_dynamic": false
  },
  "GB1164": {
    "Version": "v1.0",
    "Gb_type": "getattr with no source",
    "Context": "var_getattr {self} {name}",
    "Explanation": "Dynamo does not know how to access an attribute  on an `nn.Module` instance that lacks a source. This is  usually an internal error in Dynamo.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 322,
    "Has_dynamic": false
  },
  "GB1165": {
    "Version": "v1.0",
    "Gb_type": "getattr() on nn.Module with pending mutation",
    "Context": "getattr({obj}, {name}, {default})",
    "Explanation": "Intentionally graph breaking on getattr() on a nn.Module  with a pending mutation",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1952,
    "Has_dynamic": false
  },
  "GB1166": {
    "Version": "v1.0",
    "Gb_type": "getattr() with non-constant name argument",
    "Context": "getattr({obj}, {name_var}, {default})",
    "Explanation": "getattr() with non-constant name argument is not supported",
    "Hints": [
      "Ensure the name argument of getattr() is a string"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1928,
    "Has_dynamic": false
  },
  "GB1167": {
    "Version": "v1.0",
    "Gb_type": "id() with unsupported args",
    "Context": "str(args)",
    "Explanation": "Dynamo doesn't know how to trace id() call with args {args}",
    "Hints": [
      "Supported args are Tensors, and functions/nn.Modules/user-defined objects  from outside the compiled region."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2313,
    "Has_dynamic": false
  },
  "GB1168": {
    "Version": "v1.0",
    "Gb_type": "input iterator to itertools.cycle has too many items",
    "Context": "next({self})",
    "Explanation": "Has reached internal Dynamo max iterator limit: {MAX_ITERATOR_LIMIT}",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/iter.py",
    "Line": 375,
    "Has_dynamic": false
  },
  "GB1169": {
    "Version": "v1.0",
    "Gb_type": "invalid call to builtin op handler",
    "Context": "invalid args to {self_handler}: {args} {kwargs}",
    "Explanation": "Encountered TypeError when trying to handle op {fn.__name__}",
    "Hints": [
      "This graph break may be difficult to debug. Please report an issue to PyTorch for assistance."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 874,
    "Has_dynamic": false
  },
  "GB1170": {
    "Version": "v1.0",
    "Gb_type": "isinstance() called on user defined object with C extensions",
    "Context": "isinstance({arg}, {isinstance_type})",
    "Explanation": "User-defined object with C extensions can have torch.Tensor  attributes; intentionally graph breaking.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1814,
    "Has_dynamic": false
  },
  "GB1171": {
    "Version": "v1.0",
    "Gb_type": "issubclass() with non-constant arguments",
    "Context": "issubclass({left_ty}, {right_ty})",
    "Explanation": "issubclass() with non-constant arguments not supported.",
    "Hints": [
      "Make sure your arguments are types."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1876,
    "Has_dynamic": false
  },
  "GB1172": {
    "Version": "v1.0",
    "Gb_type": "key not found in dict",
    "Context": "Key {arg.value}",
    "Explanation": "msg",
    "Hints": [
      "Check if the key exists in the dictionary before accessing it."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/dicts.py",
    "Line": 350,
    "Has_dynamic": false
  },
  "GB1173": {
    "Version": "v1.0",
    "Gb_type": "list elements are pointing to the list itself",
    "Context": "",
    "Explanation": "Dynamo does not support lists whose items reference to itself",
    "Hints": [
      "Avoid using self referential list"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1482,
    "Has_dynamic": false
  },
  "GB1174": {
    "Version": "v1.0",
    "Gb_type": "mapping proxy affected by dictionary mutation",
    "Context": "Source: {self.source}, Dict mutation detected",
    "Explanation": "msg",
    "Hints": [
      "Avoid modifying dictionaries that might be referenced by mapping proxy objects",
      "Or avoid using the mapping proxy objects after modifying its underlying dictionary"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/dicts.py",
    "Line": 675,
    "Has_dynamic": false
  },
  "GB1175": {
    "Version": "v1.0",
    "Gb_type": "mapping proxy cannot be reconstructed",
    "Context": "Source: {self.source}",
    "Explanation": "msg",
    "Hints": [
      "Use a mapping proxy constructed in the same `torch.compile` region."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/dicts.py",
    "Line": 637,
    "Has_dynamic": false
  },
  "GB1176": {
    "Version": "v1.0",
    "Gb_type": "missing BUILD_SET handler",
    "Context": "",
    "Explanation": "Missing BUILD_SET bytecode handler (for testing purposes).",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/symbolic_convert.py",
    "Line": 2410,
    "Has_dynamic": false
  },
  "GB1177": {
    "Version": "v1.0",
    "Gb_type": "namedtuple construction",
    "Context": "{args=}, {kwargs=}",
    "Explanation": "`torch.compile` only support certain input types for namedtuple",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1701,
    "Has_dynamic": false
  },
  "GB1178": {
    "Version": "v1.0",
    "Gb_type": "non-const argument in nn.Module method",
    "Context": "call_method: {self} {name} {args} {kwargs}",
    "Explanation": "Dynamo does not support calling  method `{name}` of ``nn.Module`` {module} with non-constant arguments.",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 610,
    "Has_dynamic": false
  },
  "GB1179": {
    "Version": "v1.0",
    "Gb_type": "non-const keys in dict_keys",
    "Context": "non-const keys: {[k for k in value if not ConstantVariable.is_literal(k)]}",
    "Explanation": "Dynamo expects dict_keys keys to be constants.",
    "Hints": [
      "Ensure your dict_keys keys are constants (e.g. int, float, strings)"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 1443,
    "Has_dynamic": false
  },
  "GB1180": {
    "Version": "v1.0",
    "Gb_type": "non-const keys in mappingproxy",
    "Context": "non-const keys: {[k for k in value.keys() if not ConstantVariable.is_literal(k)]}",
    "Explanation": "Dynamo expects mappingproxy keys to be constants.",
    "Hints": [
      "Ensure your mappingproxy keys are constants (e.g. int, float, strings)"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 548,
    "Has_dynamic": false
  },
  "GB1181": {
    "Version": "v1.0",
    "Gb_type": "proxy not set",
    "Context": "as_proxy {self}",
    "Explanation": "Dynamo requires the autograd.Function context  to be initialized with a proxy.",
    "Hints": [
      "This is likely to be a Dynamo bug. Please report an issue to PyTorch."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/misc.py",
    "Line": 913,
    "Has_dynamic": false
  },
  "GB1182": {
    "Version": "v1.0",
    "Gb_type": "setattr() on Tensor.requires_grad",
    "Context": "setattr({obj}, {name}, {val})",
    "Explanation": "setattr() on Tensor.requires_grad not supported.  Mutating requires_grad can introduce a new leaf from non-leaf or vice versa in  the middle of the graph, which AOTAutograd does not currently know how to handle.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2103,
    "Has_dynamic": false
  },
  "GB1183": {
    "Version": "v1.0",
    "Gb_type": "sort with non-constant keys",
    "Context": "str(first_non_constant_key)",
    "Explanation": "Cannot perform sort with non-constant key.  First non-constant key type: {python_type}.  Most notably, we cannot sort with Tensor or SymInt keys, but we can  sort ints.",
    "Hints": [
      "Use something else as the key."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/lists.py",
    "Line": 515,
    "Has_dynamic": false
  },
  "GB1184": {
    "Version": "v1.0",
    "Gb_type": "torch.* op returned non-Tensor",
    "Context": "example_value type: {typestr(example_value)}; op: {proxy.node.op}; target: {proxy.node.target}",
    "Explanation": "torch.* ops that return a non-Tensor cannot be traced into the Dynamo FX graph output",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builder.py",
    "Line": 2846,
    "Has_dynamic": false
  },
  "GB1185": {
    "Version": "v1.0",
    "Gb_type": "torch.autograd._unsafe_preserve_version_counter escaped from compiled region",
    "Context": "str(self)",
    "Explanation": "Dynamo doesn't support compiling a region that returns  a torch.autograd._unsafe_preserve_version_counter context manager.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/ctx_manager.py",
    "Line": 1077,
    "Has_dynamic": false
  },
  "GB1186": {
    "Version": "v1.0",
    "Gb_type": "torch.distributed package is not available!",
    "Context": "",
    "Explanation": "The PyTorch package doesn't include torch.distributed when builing from source.",
    "Hints": [
      "Set USE_DISTRIBUTED=1 to enable it when building PyTorch from source."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/distributed.py",
    "Line": 59,
    "Has_dynamic": false
  },
  "GB1187": {
    "Version": "v1.0",
    "Gb_type": "torch.nn.Module with a custom __getattribute__ defined",
    "Context": "has_key_in_generic_dict {self} {key}",
    "Explanation": "Dynamo does not support checking key existence  on `nn.Module` instances that have a custom  `__getattribute__` method defined.",
    "Hints": [
      "Avoid defining `__getattribute__` in your module."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 249,
    "Has_dynamic": false
  },
  "GB1188": {
    "Version": "v1.0",
    "Gb_type": "torch.nn.Module with a non-function custom __getattr__",
    "Context": "var_getattr {self} {name}",
    "Explanation": "Dynamo detected a nn.Module object with a custom  `__getattr__` method, but this method is not a standard  Python function (e.g., it might be implemented in C/C++).  Dynamo cannot currently trace into such non-standard  `__getattr__` methods.",
    "Hints": [
      "Avoid using objects with non-standard __getattr__ methods  within the compiled region. If possible, implement  __getattr__ as a standard Python function."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/nn_module.py",
    "Line": 288,
    "Has_dynamic": false
  },
  "GB1189": {
    "Version": "v1.0",
    "Gb_type": "torch.profiler object escaped from compiled region",
    "Context": "str(self)",
    "Explanation": "Dynamo doesn't support compiling a region that returns a torch.profiler context manager.",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/ctx_manager.py",
    "Line": 953,
    "Has_dynamic": false
  },
  "GB1190": {
    "Version": "v1.0",
    "Gb_type": "unimplemented builtin op on tensor arguments",
    "Context": "partial tensor op: {self} {args} {kwargs}",
    "Explanation": "Dynamo does not know how to trace builtin operator {self.fn} with tensor arguments",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1123,
    "Has_dynamic": false
  },
  "GB1191": {
    "Version": "v1.0",
    "Gb_type": "unsupported SymNode comparison op",
    "Context": "{op.__name__}({left}, {right})",
    "Explanation": "Dynamo does not support the comparison op {op.__name__}  with SymNode arguments {left}, {right}",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2394,
    "Has_dynamic": false
  },
  "GB1192": {
    "Version": "v1.0",
    "Gb_type": "unsupported Tensor comparison op",
    "Context": "{op.__name__}({left}, {right})",
    "Explanation": "Dynamo does not support the comparison op {op.__name__}  with Tensor arguments {left}, {right}",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 2354,
    "Has_dynamic": false
  },
  "GB1193": {
    "Version": "v1.0",
    "Gb_type": "unsupported grid type for triton hop check_grid",
    "Context": "grid type = {type(grid)}",
    "Explanation": "`torch.compile` only supports list-like grid for check_grid",
    "Hints": [
      "It may be possible to write Dynamo tracing rules for this code. Please report an issue to PyTorch if you encounter this graph break often and it is causing performance issues."
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/functions.py",
    "Line": 1983,
    "Has_dynamic": false
  },
  "GB1194": {
    "Version": "v1.0",
    "Gb_type": "unsupported hasattr operation",
    "Context": "Class {self.user_cls}",
    "Explanation": "msg",
    "Hints": [
      "Consider using a regular dictionary instead"
    ],
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/dicts.py",
    "Line": 605,
    "Has_dynamic": false
  },
  "GB1195": {
    "Version": "v1.0",
    "Gb_type": "unsupported index(Tensor)",
    "Context": "",
    "Explanation": "Dynamo does not support tracing builtin index() on a Tensor",
    "Hints": "[]",
    "From_exc": null,
    "File_path": "/data/users/ssubbarao8/pytorch/torch/_dynamo/variables/builtin.py",
    "Line": 1469,
    "Has_dynamic": false
  }
}
